from fastapi import FastAPI, HTTPException, Request
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, Response, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional, Dict, Any, Union
from transformers import pipeline
import torch
import base64
import io
from PIL import Image
import httpx
import uuid
from datetime import datetime, timedelta
import asyncio
import logging
import os
from pathlib import Path
from contextlib import asynccontextmanager
import warnings

# Ø³Ø±Ú©ÙˆØ¨ warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯
logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# Ø°Ø®ÛŒØ±Ù‡ Ù…ÙˆÙ‚Øª ØªØµØ§ÙˆÛŒØ± Ø¯Ø± Ø­Ø§ÙØ¸Ù‡
image_store: Dict[str, Dict[str, Any]] = {}

# Ù…Ø¯Ù„ Gemma3n
pipe = None


# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ expand Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± home
def expand_path(path: str) -> str:
    """ØªØ¨Ø¯ÛŒÙ„ ~ Ø¨Ù‡ Ù…Ø³ÛŒØ± Ú©Ø§Ù…Ù„ home directory"""
    return str(Path(path).expanduser().resolve())


# Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² environment variables
MODEL_PATH = os.getenv("MODEL_PATH", "google/gemma-3n-e4b-it")
MAX_NEW_TOKENS = int(os.getenv("MAX_NEW_TOKENS", "2048"))
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.7"))

# Ø§Ú¯Ø± Ù…Ø³ÛŒØ± Ù„ÙˆÚ©Ø§Ù„ Ù‡Ø³ØªØŒ expand Ú©Ù†
if MODEL_PATH.startswith("~") or MODEL_PATH.startswith("/"):
    MODEL_PATH = expand_path(MODEL_PATH)
    logger.info(f"ğŸ“‚ Ù…Ø³ÛŒØ± Ù…Ø¯Ù„ Ù„ÙˆÚ©Ø§Ù„: {MODEL_PATH}")


# Lifespan context manager (Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† on_event)
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    global pipe
    logger.info("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Gemma3n-e4b...")

    try:
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù…Ø³ÛŒØ± Ù„ÙˆÚ©Ø§Ù„
        if os.path.exists(MODEL_PATH):
            logger.info(f"âœ… Ù…Ø¯Ù„ Ø§Ø² Ù…Ø³ÛŒØ± Ù„ÙˆÚ©Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯: {MODEL_PATH}")
        else:
            logger.info(f"ğŸ“¥ Ù…Ø¯Ù„ Ø§Ø² Hugging Face Hub Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯: {MODEL_PATH}")

        pipe = pipeline(
            "image-text-to-text",
            model=MODEL_PATH,
            device="auto",
            torch_dtype=torch.bfloat16,
        )
        logger.info("âœ… Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯!")
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")
        logger.error(f"ğŸ’¡ Ù…Ø³ÛŒØ± Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡: {MODEL_PATH}")
        logger.error(
            f"ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø³ÛŒØ± Ù„ÙˆÚ©Ø§Ù„ØŒ Ù…ØªØºÛŒØ± Ù…Ø­ÛŒØ·ÛŒ MODEL_PATH Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯"
        )
        pipe = None

    yield

    # Shutdown
    logger.info("ğŸ›‘ Ø¯Ø± Ø­Ø§Ù„ Ø®Ø§Ù…ÙˆØ´ Ø´Ø¯Ù† Ø³Ø±ÙˆØ±...")


# Ø³Ø§Ø®Øª Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† FastAPI Ø¨Ø§ lifespan
app = FastAPI(
    title="Nerd Agent Server",
    version="0.1.0",
    description="FastAPI backend with Gemma3n-e4b model",
    lifespan=lifespan,
)

# ØªÙ†Ø¸ÛŒÙ… CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Pydantic
class ImageUploadRequest(BaseModel):
    image: str  # base64 string


class ChatMessage(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]]]


class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    model: Optional[str] = "gemma3n-e4b"
    tools: Optional[List[Dict[str, Any]]] = None


# Middleware Ø¨Ø±Ø§ÛŒ Ù„Ø§Ú¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
@app.middleware("http")
async def log_requests(request: Request, call_next):
    logger.info(f"{request.method} {request.url.path}")
    response = await call_next(request)
    return response


# Health check
@app.get("/health")
async def health_check():
    model_status = "loaded" if pipe is not None else "not_loaded"
    return {
        "ok": True,
        "model": "gemma3n-e4b",
        "model_status": model_status,
        "timestamp": datetime.now().isoformat(),
    }


# Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±
@app.post("/api/upload-image")
async def upload_image(request: ImageUploadRequest):
    try:
        if not request.image:
            raise HTTPException(status_code=400, detail="No image provided")

        # Ø³Ø§Ø®Øª ID ÛŒÙˆÙ†ÛŒÚ©
        image_id = str(uuid.uuid4())

        # Ø°Ø®ÛŒØ±Ù‡ ØªØµÙˆÛŒØ± Ø¨Ø§ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
        image_store[image_id] = {
            "data": request.image,
            "created_at": datetime.now(),
            "expires_at": datetime.now() + timedelta(hours=1),
        }

        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø¹Ø¯ Ø§Ø² 1 Ø³Ø§Ø¹Øª
        asyncio.create_task(cleanup_image(image_id))

        image_url = f"/api/images/{image_id}"
        logger.info(f"[IMAGE] ØªØµÙˆÛŒØ± Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯: {image_id}")

        return {"url": image_url, "id": image_id}

    except Exception as e:
        logger.error(f"[IMAGE] Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ù„ÙˆØ¯: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# ØªØ§Ø¨Ø¹ Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø¹Ø¯ Ø§Ø² 1 Ø³Ø§Ø¹Øª
async def cleanup_image(image_id: str):
    await asyncio.sleep(3600)  # 1 Ø³Ø§Ø¹Øª
    if image_id in image_store:
        del image_store[image_id]
        logger.info(f"[IMAGE] ØªØµÙˆÛŒØ± Ù¾Ø§Ú© Ø´Ø¯: {image_id}")


# Ø³Ø±Ùˆ ØªØµÙˆÛŒØ±
@app.get("/api/images/{image_id}")
async def get_image(image_id: str):
    if image_id not in image_store:
        raise HTTPException(status_code=404, detail="Image not found")

    image_data = image_store[image_id]["data"]

    # Ø­Ø°Ù prefix Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡
    if "," in image_data:
        image_data = image_data.split(",")[1]

    try:
        # ØªØ¨Ø¯ÛŒÙ„ base64 Ø¨Ù‡ bytes
        image_bytes = base64.b64decode(image_data)
        return Response(content=image_bytes, media_type="image/png")

    except Exception as e:
        logger.error(f"[IMAGE] Ø®Ø·Ø§ Ø¯Ø± decode: {str(e)}")
        raise HTTPException(status_code=500, detail="Error decoding image")


# ØªØ§Ø¨Ø¹ helper Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ø§Ø² URL
async def fetch_image_as_base64(url: str) -> Optional[str]:
    try:
        # Ø§Ú¯Ø± URL Ù„ÙˆÚ©Ø§Ù„ Ù…Ø§ Ù‡Ø³ØªØŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² store Ø¨Ú¯ÛŒØ±
        if "/api/images/" in url:
            image_id = url.split("/")[-1]
            if image_id in image_store:
                data = image_store[image_id]["data"]
                # Ø­Ø°Ù prefix
                if "," in data:
                    return data.split(",")[1]
                return data

        # Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†
        async with httpx.AsyncClient() as client:
            response = await client.get(url, timeout=10.0)
            response.raise_for_status()
            image_bytes = response.content
            return base64.b64encode(image_bytes).decode("utf-8")

    except Exception as e:
        logger.error(f"[IMAGE] Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±: {str(e)}")
        return None


# ØªØ§Ø¨Ø¹ ØªØ¨Ø¯ÛŒÙ„ base64 Ø¨Ù‡ PIL Image
def base64_to_pil(base64_str: str) -> Image.Image:
    # Ø­Ø°Ù prefix Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù‡
    if "," in base64_str:
        base64_str = base64_str.split(",")[1]

    image_bytes = base64.b64decode(base64_str)
    image = Image.open(io.BytesIO(image_bytes))
    return image


# Chat API
@app.post("/api/chat")
async def chat(request: ChatRequest):
    start_time = datetime.now()
    logger.info(f"[CHAT] Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ú†Øª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ - ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§: {len(request.messages)}")

    if pipe is None:
        raise HTTPException(
            status_code=503, detail="Ù…Ø¯Ù„ Ù‡Ù†ÙˆØ² Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§ ØµØ¨Ø± Ú©Ù†ÛŒØ¯."
        )

    try:
        # ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Gemma
        formatted_messages = []

        for msg in request.messages:
            formatted_msg = {"role": msg.role, "content": []}

            if isinstance(msg.content, str):
                # ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…ÛŒ - ÙÙ‚Ø· Ù…ØªÙ†
                formatted_msg["content"].append({"type": "text", "text": msg.content})

            elif isinstance(msg.content, list):
                # ÙØ±Ù…Øª Ø¬Ø¯ÛŒØ¯ - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ùˆ ØªØµØ§ÙˆÛŒØ±
                for part in msg.content:
                    if part.get("type") == "text":
                        formatted_msg["content"].append(
                            {"type": "text", "text": part.get("text", "")}
                        )

                    elif part.get("type") == "image":
                        image_url = part.get("url", "")
                        logger.info(f"[CHAT] Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ø§Ø²: {image_url}")

                        # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ±
                        base64_image = await fetch_image_as_base64(image_url)

                        if base64_image:
                            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ PIL Image
                            try:
                                pil_image = base64_to_pil(base64_image)
                                formatted_msg["content"].append(
                                    {"type": "image", "image": pil_image}
                                )
                                logger.info("[CHAT] ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯")
                            except Exception as e:
                                logger.error(f"[CHAT] Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±: {e}")

            formatted_messages.append(formatted_msg)

        logger.info("[CHAT] Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Gemma3n...")

        # ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„
        output = pipe(
            text=formatted_messages,
            max_new_tokens=2048,
            do_sample=True,
            temperature=0.7,
        )

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø§Ø³Ø®
        generated_text = output[0]["generated_text"][-1]["content"]

        duration = (datetime.now() - start_time).total_seconds()
        logger.info(f"[CHAT] âœ… Ù¾Ø§Ø³Ø® Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ Ø¯Ø± {duration:.2f}s")
        logger.info(f'[CHAT] Ù…Ø­ØªÙˆØ§: "{generated_text[:100]}..."')

        # Ø³Ø§Ø®Øª Ù¾Ø§Ø³Ø® Ø¨Ù‡ ÙØ±Ù…Øª Ù…Ø´Ø§Ø¨Ù‡ Ollama
        response_data = {
            "message": {"role": "assistant", "content": generated_text},
            "model": request.model,
            "created_at": datetime.now().isoformat(),
            "done": True,
            "duration_seconds": duration,
        }

        return JSONResponse(content=response_data)

    except Exception as e:
        logger.error(f"[CHAT] âŒ Ø®Ø·Ø§ Ø¯Ø± Ú†Øª: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}")


# Ø³Ø±Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ©
app.mount("/static", StaticFiles(directory="public"), name="static")


# ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ
@app.get("/", response_class=HTMLResponse)
async def serve_index():
    try:
        with open("public/index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        return HTMLResponse(
            content="<h1>Welcome to Nerd Agent Server</h1><p>Frontend files not found</p>",
            status_code=404,
        )


# Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÙˆØ±
if __name__ == "__main__":
    import uvicorn

    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  ğŸš€ Nerd Agent Server (FastAPI + Gemma3n)      â•‘")
    print("â•‘  ğŸ“ http://localhost:8000                       â•‘")
    print("â•‘  ğŸ¤– Model: google/gemma-3n-e4b-it              â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True, log_level="info")
